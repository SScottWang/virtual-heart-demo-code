{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Tokenization\n",
    "\n",
    "This notebook demonstrates how to preprocess mouse spatial transcriptomics data and tokenize it for Geneformer analysis.\n",
    "\n",
    "## Pipeline Overview:\n",
    "1. Load raw data\n",
    "2. Add QC metrics\n",
    "3. Convert mouse gene symbols to human Ensembl IDs\n",
    "4. Tokenization\n",
    "5. Verify results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wsg/software/miniconda3/envs/Geneformer/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "from geneformer_utils import DataPreprocessor, tokenize_data\n",
    "from datasets import load_from_disk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input/Output paths\n",
    "INPUT_H5AD = \"/home/wsg/SSW/data/mouse_E9.5_heart/mouse_E9.5_heart.h5ad\"\n",
    "MGI_FILE = \"/home/wsg/SSW/data/HOM_MouseHumanSequence.rpt\"\n",
    "OUTPUT_DIR = \"/home/wsg/SSW/data/mouse_E9.5_heart/token\"\n",
    "OUTPUT_PREFIX = \"mouse_E9p5_heart\"\n",
    "\n",
    "# Specify the layer containing raw counts (None if using adata.X)\n",
    "COUNT_LAYER = \"total\"\n",
    "\n",
    "# Custom attribute mapping for tokenized data\n",
    "CUSTOM_ATTRS = {\n",
    "    \"heart_regions\": \"cell_type\",\n",
    "    \"heart_anno\": \"organ\",\n",
    "    \"n_counts\": \"n_counts\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative configuration for E11.5 dataset\n",
    "INPUT_H5AD = \"/home/wsg/SSW/data/mouse_E11.5_heart/mouse_E11.5_heart.h5ad\"\n",
    "MGI_FILE = \"/home/wsg/SSW/data/HOM_MouseHumanSequence.rpt\"\n",
    "OUTPUT_DIR = \"/home/wsg/SSW/data/mouse_E11.5_heart/token\"\n",
    "OUTPUT_PREFIX = \"mouse_E11p5_heart\"\n",
    "\n",
    "COUNT_LAYER = \"total\"\n",
    "\n",
    "CUSTOM_ATTRS = {\n",
    "    \"heart_regions\": \"cell_type\",\n",
    "    \"heart_anno\": \"organ\",\n",
    "    \"n_counts\": \"n_counts\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Loading data...\n",
      "âœ… Data loaded: 98966 cells Ã— 19746 genes\n",
      "\n",
      "Observations (first 5):\n",
      "                             ctype_user    cml     slices heart_anno  \\\n",
      "slice_40_80591  Cardiac muscle lineages    cml  slices_40      Heart   \n",
      "slice_40_80762  Cardiac muscle lineages    cml  slices_40      Heart   \n",
      "slice_40_80888  Cardiac muscle lineages    cml  slices_40      Heart   \n",
      "slice_40_80908  Cardiac muscle lineages    cml  slices_40      Heart   \n",
      "slice_40_80909                 Myocytes  other  slices_40      Heart   \n",
      "\n",
      "                 heart_regions  stage  3d_spatial_density_heart_regions  \n",
      "slice_40_80591  Left ventricle  E11.5                          0.627947  \n",
      "slice_40_80762  Left ventricle  E11.5                          0.632751  \n",
      "slice_40_80888  Left ventricle  E11.5                          0.558212  \n",
      "slice_40_80908  Left ventricle  E11.5                          0.554837  \n",
      "slice_40_80909     Left atrium  E11.5                          0.246904  \n",
      "\n",
      "Variable names (first 5): ['0610005C13Rik', '0610006L08Rik', '0610009B22Rik', '0610009O20Rik', '0610010F05Rik']\n"
     ]
    }
   ],
   "source": [
    "print(\"ðŸ“‚ Loading data...\")\n",
    "adata = sc.read_h5ad(INPUT_H5AD)\n",
    "print(f\"âœ… Data loaded: {adata.n_obs} cells Ã— {adata.n_vars} genes\")\n",
    "print(f\"\\nObservations (first 5):\")\n",
    "print(adata.obs.head())\n",
    "print(f\"\\nVariable names (first 5): {list(adata.var_names[:5])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "### 2.1 Add QC Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding QC metrics...\n",
      "Moving counts from layer 'total' to adata.X...\n",
      "Calculating n_counts and n_genes...\n",
      "âœ… QC metrics added. n_counts range: [108, 4124]\n"
     ]
    }
   ],
   "source": [
    "preprocessor = DataPreprocessor(mgi_file_path=MGI_FILE)\n",
    "\n",
    "# Add QC metrics (n_counts, filter_pass, etc.)\n",
    "adata = preprocessor.add_qc_metrics(adata, count_layer=COUNT_LAYER)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Gene ID Conversion: Mouse Symbol â†’ Human Ensembl ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Converting Mouse Symbol -> Human Ensembl ID...\n",
      "Input: 19746 mouse genes\n",
      "Step 1: Parsing MGI ortholog file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input sequence provided is already in string format. No operation performed\n",
      "Input sequence provided is already in string format. No operation performed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Found 20181 ortholog pairs\n",
      "Step 2: Converting Human Symbol -> Ensembl ID...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "409 input query terms found dup hits:\t[('RAN', 3), ('SYCP3', 5), ('ZNF670', 6), ('C19orf48P', 2), ('ATXN1-AS1', 2), ('SCYGR9', 2), ('ABCA1\n",
      "15 input query terms found no hit:\t['FAM210A', 'FAM210B', 'ATP6', 'ATP8', 'COX1', 'COX2', 'COX3', 'CYTB', 'ND1', 'ND2', 'ND3', 'ND4', '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 3: Applying mapping...\n",
      "ðŸŽ‰ Result: 16490 / 19746 genes successfully mapped\n",
      "âœ… Ready! Gene IDs example: ['ENSG00000168887', 'ENSG00000248713', 'ENSG00000110696', 'ENSG00000180044', 'ENSG00000291362']\n",
      "\n",
      "âœ… Conversion complete!\n",
      "Final: 98966 cells Ã— 16490 genes\n",
      "\n",
      "Gene IDs (first 5): ['ENSG00000168887', 'ENSG00000248713', 'ENSG00000110696', 'ENSG00000180044', 'ENSG00000291362']\n",
      "Mouse symbols preserved in adata.var['mouse_symbol']\n"
     ]
    }
   ],
   "source": [
    "# Convert gene IDs\n",
    "adata = preprocessor.convert_mouse_to_human_ensembl(adata)\n",
    "\n",
    "print(f\"\\nâœ… Conversion complete!\")\n",
    "print(f\"Final: {adata.n_obs} cells Ã— {adata.n_vars} genes\")\n",
    "print(f\"\\nGene IDs (first 5): {list(adata.var_names[:5])}\")\n",
    "print(f\"Mouse symbols preserved in adata.var['mouse_symbol']\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save Preprocessed Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Preprocessed data saved to: /home/wsg/SSW/data/mouse_E11.5_heart/token/mouse_E11p5_heart_ensembl_id.h5ad\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "preprocessed_path = f\"{OUTPUT_DIR}/{OUTPUT_PREFIX}_ensembl_id.h5ad\"\n",
    "adata.write_h5ad(preprocessed_path)\n",
    "print(f\"âœ… Preprocessed data saved to: {preprocessed_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tokenization\n",
    "\n",
    "Convert preprocessed data into token sequences for Geneformer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Tokenizing data from /home/wsg/SSW/data/mouse_E11.5_heart/token...\n",
      "Tokenizing /home/wsg/SSW/data/mouse_E11.5_heart/token/mouse_E11p5_heart_ensembl_id.h5ad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wsg/software/miniconda3/envs/Geneformer/lib/python3.10/site-packages/geneformer/tokenizer.py:544: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  for i in adata.var[\"ensembl_id_collapsed\"][coding_miRNA_loc]\n",
      "/home/wsg/software/miniconda3/envs/Geneformer/lib/python3.10/site-packages/geneformer/tokenizer.py:547: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  coding_miRNA_ids = adata.var[\"ensembl_id_collapsed\"][coding_miRNA_loc]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset.\n",
      "âœ… Tokenization complete! Output: /home/wsg/SSW/data/mouse_E11.5_heart/token/mouse_E11p5_heart.dataset\n"
     ]
    }
   ],
   "source": [
    "tokenize_data(\n",
    "    input_dir=OUTPUT_DIR,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    output_prefix=OUTPUT_PREFIX,\n",
    "    custom_attr_dict=CUSTOM_ATTRS,\n",
    "    file_format=\"h5ad\",\n",
    "    nproc=16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verify Tokenization Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Loading tokenized dataset from /home/wsg/SSW/data/mouse_E11.5_heart/token/mouse_E11p5_heart.dataset...\n",
      "\n",
      "=== Dataset Overview ===\n",
      "Dataset({\n",
      "    features: ['input_ids', 'cell_type', 'organ', 'n_counts', 'length'],\n",
      "    num_rows: 98966\n",
      "})\n",
      "\n",
      "=== First Cell Example ===\n",
      "Columns: ['input_ids', 'cell_type', 'organ', 'n_counts', 'length']\n",
      "\n",
      "Token sequence length: 971\n",
      "First 10 tokens: [2, 297, 6594, 12127, 12693, 7749, 18836, 10170, 4819, 1864]\n",
      "\n",
      "Metadata:\n",
      "  cell_type: Left ventricle\n",
      "  organ: Heart\n",
      "  n_counts: 2060.0\n",
      "  length: 971\n",
      "\n",
      "âœ… Tokenization verified successfully!\n"
     ]
    }
   ],
   "source": [
    "dataset_path = f\"{OUTPUT_DIR}/{OUTPUT_PREFIX}.dataset\"\n",
    "\n",
    "print(f\"ðŸ“‚ Loading tokenized dataset from {dataset_path}...\")\n",
    "dataset = load_from_disk(dataset_path)\n",
    "\n",
    "print(\"\\n=== Dataset Overview ===\")\n",
    "print(dataset)\n",
    "\n",
    "print(\"\\n=== First Cell Example ===\")\n",
    "first_cell = dataset[0]\n",
    "print(f\"Columns: {list(first_cell.keys())}\")\n",
    "print(f\"\\nToken sequence length: {len(first_cell['input_ids'])}\")\n",
    "print(f\"First 10 tokens: {first_cell['input_ids'][:10]}\")\n",
    "print(f\"\\nMetadata:\")\n",
    "for key, value in first_cell.items():\n",
    "    if key != 'input_ids':\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nâœ… Tokenization verified successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python (Geneformer)",
   "language": "python",
   "name": "geneformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
